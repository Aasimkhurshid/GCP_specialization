{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Collaborative filtering on Google Analytics data\n",
    "\n",
    "This notebook demonstrates how to implement a WALS matrix refactorization approach to do collaborative filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "PROJECT = \"qwiklabs-gcp-03-2787a45a1534\" # REPLACE WITH YOUR PROJECT ID\n",
    "BUCKET = \"qwiklabs-gcp-03-2787a45a1534\" # REPLACE WITH YOUR BUCKET NAME\n",
    "REGION = \"us-central1\" # REPLACE WITH YOUR BUCKET REGION e.g. us-central1\n",
    "\n",
    "# Do not change these\n",
    "os.environ[\"PROJECT\"] = PROJECT\n",
    "os.environ[\"BUCKET\"] = BUCKET\n",
    "os.environ[\"REGION\"] = REGION\n",
    "os.environ[\"TFVERSION\"] = \"1.13\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n",
      "Updated property [compute/region].\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gcloud config set project $PROJECT\n",
    "gcloud config set compute/region $REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.5\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Create raw dataset\n",
    "<p>\n",
    "For collaborative filtering, we don't need to know anything about either the users or the content. Essentially, all we need to know is userId, itemId, and rating that the particular user gave the particular item.\n",
    "<p>\n",
    "In this case, we are working with newspaper articles. The company doesn't ask their users to rate the articles. However, we can use the time-spent on the page as a proxy for rating.\n",
    "<p>\n",
    "Normally, we would also add a time filter to this (\"latest 7 days\"), but our dataset is itself limited to a few days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>visitorId</th>\n",
       "      <th>contentId</th>\n",
       "      <th>session_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1031539128969021923-1</td>\n",
       "      <td>299918857</td>\n",
       "      <td>46074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1655026264169370690-165</td>\n",
       "      <td>299170525</td>\n",
       "      <td>28438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1777072527276763113-113</td>\n",
       "      <td>299827911</td>\n",
       "      <td>6698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1818199630884742957-45</td>\n",
       "      <td>299936493</td>\n",
       "      <td>42307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2211768598185554204-465</td>\n",
       "      <td>255478055</td>\n",
       "      <td>155887</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 visitorId  contentId  session_duration\n",
       "0    1031539128969021923-1  299918857             46074\n",
       "1  1655026264169370690-165  299170525             28438\n",
       "2  1777072527276763113-113  299827911              6698\n",
       "3   1818199630884742957-45  299936493             42307\n",
       "4  2211768598185554204-465  255478055            155887"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "bq = bigquery.Client(project = PROJECT)\n",
    "\n",
    "sql = \"\"\"\n",
    "WITH CTE_visitor_page_content AS (\n",
    "    SELECT\n",
    "        # Schema: https://support.google.com/analytics/answer/3437719?hl=en\n",
    "        # For a completely unique visit-session ID, we combine combination of fullVisitorId and visitNumber:\n",
    "        CONCAT(fullVisitorID,'-',CAST(visitNumber AS STRING)) AS visitorId,\n",
    "        (SELECT MAX(IF(index=10, value, NULL)) FROM UNNEST(hits.customDimensions)) AS latestContentId,  \n",
    "        (LEAD(hits.time, 1) OVER (PARTITION BY fullVisitorId ORDER BY hits.time ASC) - hits.time) AS session_duration \n",
    "    FROM\n",
    "        `cloud-training-demos.GA360_test.ga_sessions_sample`,   \n",
    "        UNNEST(hits) AS hits\n",
    "    WHERE \n",
    "        # only include hits on pages\n",
    "        hits.type = \"PAGE\"\n",
    "GROUP BY   \n",
    "        fullVisitorId,\n",
    "        visitNumber,\n",
    "        latestContentId,\n",
    "        hits.time )\n",
    "-- Aggregate web stats\n",
    "SELECT   \n",
    "    visitorId,\n",
    "    latestContentId as contentId,\n",
    "    SUM(session_duration) AS session_duration\n",
    "FROM\n",
    "    CTE_visitor_page_content\n",
    "WHERE\n",
    "    latestContentId IS NOT NULL \n",
    "GROUP BY\n",
    "    visitorId, \n",
    "    latestContentId\n",
    "HAVING \n",
    "    session_duration > 0\n",
    "\"\"\"\n",
    "\n",
    "df = bq.query(sql).to_dataframe()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.843020e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.247962e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.311864e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.607700e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.626050e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.271750e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.690598e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       session_duration\n",
       "count      2.843020e+05\n",
       "mean       1.247962e+05\n",
       "std        2.311864e+05\n",
       "min        1.000000e+00\n",
       "25%        1.607700e+04\n",
       "50%        5.626050e+04\n",
       "75%        1.271750e+05\n",
       "max        7.690598e+06"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats = df.describe()\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfQAAAE8CAYAAAA2bUNTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAdvUlEQVR4nO3df7RXdZ3v8edbQAmrYylTKhI2IEaAoEc07fojs/AaWdaUpK1V44Vxlf1cmVTTrbvWjON1dZsZl4wNGTH9GEXNUkYmy7mSP0IFFJcQaKQUJ7wjUR5/XArR9/3jfOWeLx443+853y/77M3zsRbL7/58z97f9+bIeZ3PZ3/2/kRmIkmSym2/oguQJEmDZ6BLklQBBrokSRVgoEuSVAEGuiRJFWCgS5JUAcOLLmAwDjnkkBw3blzRZUiStFesWrXqd5k5uq/3ShnoETELmDV+/HhWrlxZdDmSJO0VEfHr3b1XyiH3zFySmXM7OjqKLkWSpCGhlIEuSZLqGeiSJFVAKa+hS5Lg+eefp6uriz/+8Y9Fl6IWGzlyJGPGjGHEiBEN72OgS1JJdXV18apXvYpx48YREUWXoxbJTLZu3UpXVxdHHnlkw/s55C5JJfXHP/6Rgw8+2DCvmIjg4IMPbnrkxUCXpBIzzKtpIN/XUgZ6RMyKiAXd3d1FlyJJ0pBQymvombkEWNLZ2Tmn6FokaagYN+/Wlh5v4+Vnt/R4jdq8eTOf/OQnufHGG9ty/EWLFrFy5Uquuuqqlhzvsssu44tf/OLO7ZNOOomf//znLTl2M0rZQ5ckVddhhx3WtjAfiBdeeGGP71922WV120WEORjodcbNu7XujyRpz5577jnOPvtsjjnmGCZPnszixYtZtWoVp556KscddxzvfOc7eeKJJwC48sormTRpElOnTuW8884D4Gc/+xnTpk1j2rRpTJ8+nWeeeYaNGzcyefJkoGfi30c/+lGmTJnC9OnTueOOO4CeXva5557LzJkzmTBhAp///Of3WOe3v/1tjjrqKE499VTuueeene0f+chH6n55eOUrXwnAsmXLOP300/nQhz7ElClTAHjPe97Dcccdx5vf/GYWLFgAwLx589i2bRvTpk3j/PPPrztGZnLJJZcwefJkpkyZwuLFi3ce+7TTTuP9738/Rx99NOeffz6ZOYjvQo9SDrlLkoaGH//4xxx22GHcemtPJ6i7u5uzzjqLm2++mdGjR7N48WK+9KUvsXDhQi6//HIef/xxDjjgAJ566ikAvva1rzF//nxOPvlknn32WUaOHFl3/Pnz5wPw8MMPs379et7xjnfw6KOPArB69WoefPBBDjjgACZOnMgnPvEJjjjiiJfV+MQTT/CVr3yFVatW0dHRwemnn8706dP7Pbf777+fNWvW7Lx1bOHChbz2ta9l27ZtHH/88bzvfe/j8ssv56qrrmL16tUv2/+mm25i9erVPPTQQ/zud7/j+OOP55RTTgHgwQcfZO3atRx22GGcfPLJ3HPPPbz1rW9t7C99N+yhS5IGbMqUKdx+++1ceuml3HXXXWzatIk1a9Zw5plnMm3aNP7mb/6Grq4uAKZOncr555/P9773PYYP7+lPnnzyyXz2s5/lyiuv5KmnntrZ/pK7776bD3/4wwAcffTRvOENb9gZ6GeccQYdHR2MHDmSSZMm8etf971uyX333cdpp53G6NGj2X///fngBz/Y0LnNmDGj7j7wK6+8kmOOOYYTTzyRTZs28ctf/nKP+999993Mnj2bYcOG8brXvY5TTz2VFStW7Dz2mDFj2G+//Zg2bRobN25sqKY9MdAlSQN21FFHsWrVKqZMmcIXvvAFfvCDH/DmN7+Z1atXs3r1ah5++GF+8pOfAHDrrbfy8Y9/nFWrVnHcccexY8cO5s2bxzXXXMO2bds48cQTWb9+fd3x9zQUfcABB+x8PWzYMHbs2LHbr93dbWDDhw/nxRdf3PlZ27dv3/negQceuPP1smXLuP3221m+fDkPPfQQ06dP7/c+8VbV3igDXZI0YJs3b2bUqFFccMEFfO5zn+O+++5jy5YtLF++HOh5PO3atWt58cUX2bRpE6effjpXXHEFTz31FM8++yy/+tWvmDJlCpdeeimdnZ0vC/RTTjmF73//+wA8+uij/OY3v2HixIlN1XjCCSewbNkytm7dyvPPP88NN9yw871x48axatUqAG6++Waef/75Po/R3d3Na17zGkaNGsX69eu59957d743YsSIPvc75ZRTWLx4MS+88AJbtmzhzjvvZMaMGU3V3gyvoUtSRRRxm9nDDz/MJZdcwn777ceIESO4+uqrGT58OJ/85Cfp7u5mx44dfPrTn+aoo47iggsuoLu7m8zkM5/5DAcddBBf/vKXueOOOxg2bBiTJk3irLPO2jmJDuBjH/sYF110EVOmTGH48OEsWrSornfbiEMPPZSvfvWrvOUtb+HQQw/l2GOP3Tlzfc6cOZxzzjnMmDGDM844o65X3tvMmTP5xje+wdSpU5k4cSInnnjizvfmzp3L1KlTOfbYY3f+8gHw3ve+l+XLl3PMMccQEVxxxRW8/vWvf9kvLa0SrZhZV5TOzs5cuXJly46368z2ou7BlKRGrFu3jje96U1Fl6E26ev7GxGrMrOzr68fMkPuEXFaRNwVEd+IiNOKrkeSpDJp65B7RCwE3gU8mZmTe7XPBP4RGAZck5mXAwk8C4wEutpZlySpmk444QT+9Kc/1bV997vf3XkveZW1+xr6IuAq4DsvNUTEMGA+cCY9wb0iIm4B7srMn0XE64CvA+e3uTZJUsXcd999RZdQmLYOuWfmncDvd2meAWzIzMcycztwHXBOZr5Ye/8PQHMzHiRpH1XmeVDavYF8X4uY5X44sKnXdhdwQkScC7wTOIieXn2fImIuMBdg7Nix7atSkoa4kSNHsnXrVtdEr5jMZOvWrS97al5/igj0vv6vy8y8Cbipv50zcwGwAHpmube4NkkqjTFjxtDV1cWWLVuKLkUtNnLkSMaMGdPUPkUEehfQ+2G7Y4DNzRwgImYBs8aPH9/KuiSpVEaMGFH3aFLt24q4bW0FMCEijoyI/YHzgFuaOUBmLsnMuR0dHW0pUJKksmlroEfEtcByYGJEdEXEhZm5A7gYuA1YB1yfmWvbWYckSVXX1iH3zJy9m/alwNKBHtchd0mS6g2ZJ8U1wyF3SZLqlTLQI2JWRCzo7u4uuhRJkoaEUga6PXRJkuqVMtAlSVI9A12SpAoo4sEyg7a3Zrm7ProkqSxK2UP3GrokSfVKGeiSJKleKQPd29YkSapXykB3yF2SpHqlDHRJklTPQJckqQIMdEmSKqCUge6kOEmS6pUy0J0UJ0lSvVIGuiRJqmegS5JUAQa6JEkVYKBLklQBpQx0Z7lLklSvlIHuLHdJkuqVMtAlSVI9A12SpAow0CVJqgADXZKkChhedAFlMm7erS9r23j52QVUIklSPXvokiRVQCkD3fvQJUmqV8pA9z50SZLqlTLQJUlSPQNdkqQKMNAlSaoAA12SpAow0CVJqgADXZKkCjDQJUmqAANdkqQKGFKBHhEHRsSqiHhX0bVIklQmbQ30iFgYEU9GxJpd2mdGxCMRsSEi5vV661Lg+nbWJElSFbW7h74ImNm7ISKGAfOBs4BJwOyImBQRbwd+Afxnm2uSJKly2rp8ambeGRHjdmmeAWzIzMcAIuI64BzglcCB9IT8tohYmpkvtrM+SZKqooj10A8HNvXa7gJOyMyLASLiI8DvdhfmETEXmAswduzY9lbagF3XSHd9dElSEYqYFBd9tOXOF5mLMvPfdrdzZi7IzM7M7Bw9enRbCpQkqWyKCPQu4Ihe22OAzQXUIUlSZRQR6CuACRFxZETsD5wH3NLMASJiVkQs6O7ubkuBkiSVTbtvW7sWWA5MjIiuiLgwM3cAFwO3AeuA6zNzbTPHzcwlmTm3o6Oj9UVLklRC7Z7lPns37UuBpQM9bkTMAmaNHz9+oIeQJKlShtST4hplD12SpHqlDHRJklSvlIHupDhJkuqVMtAdcpckqV4pA12SJNUrZaA75C5JUr0inuU+aJm5BFjS2dk5p+haduWz3SVJRShlD12SJNUz0CVJqoBSBrrX0CVJqlfKQPe2NUmS6pUy0CVJUj0DXZKkCihloHsNXZKkeqUMdK+hS5JUr5QPlikTHzQjSdobStlDlyRJ9Qx0SZIqwECXJKkCShnoznKXJKleKQPdWe6SJNUrZaBLkqR63ra2l3kbmySpHeyhS5JUAQa6JEkVYKBLklQBBrokSRVQykD3PnRJkuqVcpZ7Zi4BlnR2ds4pupbBcta7JKkVStlDlyRJ9Qx0SZIqwECXJKkCDHRJkiqglJPiqsxJcpKkgbCHLklSBRjokiRVQEOBHhGT212IJEkauEZ76N+IiPsj4mMRcVA7C5IkSc1raFJcZr41IiYAfwmsjIj7gW9n5k9bVUhEvAn4FHAI8B+ZeXWrjl1mTpKTJDWi4WvomflL4K+BS4FTgSsjYn1EnLu7fSJiYUQ8GRFrdmmfGRGPRMSGiJhXO/66zLwI+ADQOZCTkSRpX9XoNfSpEfH3wDrgbcCszHxT7fXf72HXRcDMXY41DJgPnAVMAmZHxKTae+8G7gb+o7nTkCRp39ZoD/0q4AHgmMz8eGY+AJCZm+nptfcpM+8Efr9L8wxgQ2Y+lpnbgeuAc2pff0tmngSc39xpSJK0b2v0wTL/FdiWmS8ARMR+wMjM/L+Z+d0mP/NwYFOv7S7ghIg4DTgXOABYurudI2IuMBdg7NixTX50+XlNXZLUl0YD/Xbg7cCzte1RwE+AkwbwmdFHW2bmMmBZfztn5gJgAUBnZ2cO4PMlSaqcRgN9ZGa+FOZk5rMRMWqAn9kFHNFrewywuZkDRMQsYNb48eMHWEJ12GOXJEHj19Cfi4hjX9qIiOOAbQP8zBXAhIg4MiL2B84DbmnmAJm5JDPndnR0DLAESZKqpdEe+qeBGyLipZ70ocAH+9spIq4FTgMOiYgu4CuZ+a2IuBi4DRgGLMzMtc0UbQ9dkqR6kdnYZeiIGAFMpOca+PrMfL6dhTWis7MzV65c2bLj7Tp8XQUOwUtSdUTEqszs81ktzSyfejwwrrbP9IggM7/TgvokSdIgNRToEfFd4M+B1cALteYECgl0h9wb56Q5Sdo3NNpD7wQmZaPj822WmUuAJZ2dnXOKrkWSpKGg0Vnua4DXt7MQSZI0cI320A8BflFbZe1PLzVm5rvbUlU/HHKXJKleo4H+1XYW0SyH3Aeuv5n8XmOXpHJqdD30n0XEG4AJmXl77Slxw9pbmiRJalSjy6fOAW4E/rnWdDjwozbVJEmSmtTokPvH6Vn29D6AzPxlRPxZ26rqh9fQ28cheUkqp0Znuf+ptnY5ABExnJ770Avhs9wlSarXaKD/LCK+CLwiIs4EbgCWtK8sSZLUjEaH3OcBFwIPA38FLAWuaVdRGrp88pwkDU2NznJ/Efhm7U/hvIYuSVK9Rp/l/jh9XDPPzDe2vKIGeB/60NHICnX24iWp/Zp5lvtLRgJ/Aby29eWoihyml6T2a2hSXGZu7fXnt5n5D8Db2luaJElqVKND7sf22tyPnh77q9pSkSrPHrsktV6jQ+7/q9frHcBG4AMtr0aSJA1Io7PcT293Ic1wlrskSfUaHXL/7J7ez8yvt6acxjjLXZKkes3Mcj8euKW2PQu4E9jUjqIkSVJzGg30Q4BjM/MZgIj4KnBDZv63dhUmSZIa1+iz3McC23ttbwfGtbwaSZI0II320L8L3B8RP6TniXHvBb7TtqokSVJTGp3l/rcR8e/Af6k1fTQzH2xfWZIkqRmNDrkDjAKezsx/BLoi4sg21SRJkprUUKBHxFeAS4Ev1JpGAN9rV1GSJKk5jfbQ3wu8G3gOIDM3U+CjXyNiVkQs6O7uLqoESZKGlEYDfXtmJrUlVCPiwPaV1L/MXJKZczs6OoosQ5KkIaPRWe7XR8Q/AwdFxBzgL4Fvtq8s7UtcrEWSBq/fQI+IABYDRwNPAxOB/56ZP21zbZIkqUH9BnpmZkT8KDOPAwxxSZKGoEavod8bEce3tRJJkjRgjV5DPx24KCI20jPTPejpvE9tV2GSJKlxewz0iBibmb8BztpL9UiSpAHor4f+I3pWWft1RPwgM9+3F2qSJElN6u8aevR6/cZ2FiJJkgauv0DP3bxui4h4T0R8MyJujoh3tPvzJEmqiv4C/ZiIeDoingGm1l4/HRHPRMTTjXxARCyMiCcjYs0u7TMj4pGI2BAR8wAy80eZOQf4CPDBAZyPJEn7pD0GemYOy8xXZ+arMnN47fVL269u8DMWATN7N0TEMGA+PZPtJgGzI2JSry/569r7kiSpAc0snzogmXkn8PtdmmcAGzLzsczcDlwHnBM9/ifw75n5QLtrkySpKtoe6LtxOLCp13ZXre0TwNuB90fERX3tGBFzI2JlRKzcsmVL+yuVJKkEGn2wTKtFH22ZmVcCV+5px8xcACwA6OzsbPtEPUmSyqCoHnoXcESv7THA5kZ3dj10SZLqFRXoK4AJEXFkROwPnAfc0ujOrocuSVK9tgd6RFwLLAcmRkRXRFyYmTuAi4HbgHXA9Zm5tolj2kOXJKmXtl9Dz8zZu2lfCiwd4DGXAEs6OzvnDKY2SZKqoqghd0mS1EKlDHSH3CVJqlfKQHdSnCRJ9UoZ6JIkqV4pA90hd0mS6hX1pLhBcZZ7tY2bd2vd9sbLzy6oEkkqj1L20CVJUj0DXZKkCihloHsNXZKkel5D15DnNXVJ6l8pe+iSJKmegS5JUgUY6JIkVUApA91JcZIk1XNSnErHSXKS9HKl7KFLkqR6BrokSRVgoEuSVAEGuiRJFVDKQHeWuyRJ9UoZ6Jm5JDPndnR0FF2KJElDQikDXZIk1TPQJUmqgFI+WEbaEx88I2lfZA9dkqQKsIeuyrPHLmlfYKCr9HYNbEnaF5VyyN370CVJqlfKQPc+dEmS6pUy0CVJUj0DXZKkCjDQJUmqAANdkqQK8LY1aRfety6pjOyhS5JUAQa6JEkVYKBLklQBQ+YaekS8EfgS0JGZ7y+6HlVXs9fIvaYuqQza2kOPiIUR8WRErNmlfWZEPBIRGyJiHkBmPpaZF7azHkmSqqrdPfRFwFXAd15qiIhhwHzgTKALWBERt2TmL9pci1SIvhaPsZcvqdXa2kPPzDuB3+/SPAPYUOuRbweuA85pZx2SJFVdEdfQDwc29druAk6IiIOBvwWmR8QXMvPv+to5IuYCcwHGjh3b7lqlfnmNXdJQUESgRx9tmZlbgYv62zkzFwALADo7O7PFtUmSVEpFBHoXcESv7THA5mYOEBGzgFnjx49vZV3aR/V1jVuSyqaI+9BXABMi4siI2B84D7ilmQO4HrokSfXafdvatcByYGJEdEXEhZm5A7gYuA1YB1yfmWvbWYckSVXX1iH3zJy9m/alwNKBHtchdw1lDuFLKkIpH/3qkLskSfVKGeiSJKnekHmWezMccleRHFKXNBSVsofukLskSfVKGeiSJKleKQM9ImZFxILu7u6iS5EkaUgoZaA75C5JUr1SBrokSarnLHepAM2u0OaKbpL6U8oeukPukiTVK2WgS5Kkega6JEkVYKBLklQBpQx070OXJKleKQPdSXGSJNUrZaBLkqR6BrokSRVgoEuSVAEGuiRJFeCjX6UhaNdHvTb79T4aVtr3lLKH7ix3SZLqlTLQJUlSPQNdkqQKMNAlSaoAA12SpAow0CVJqgADXZKkCvA+dKmCvC9d2veUsofufeiSJNUrZaBLkqR6BrokSRVgoEuSVAEGuiRJFWCgS5JUAQa6JEkVYKBLklQBBrokSRVgoEuSVAFD5tGvEXEg8E/AdmBZZn6/4JIkSSqNtvbQI2JhRDwZEWt2aZ8ZEY9ExIaImFdrPhe4MTPnAO9uZ12SJFVNu4fcFwEzezdExDBgPnAWMAmYHRGTgDHAptqXvdDmuiRJqpS2Drln5p0RMW6X5hnAhsx8DCAirgPOAbroCfXV7OEXjYiYC8wFGDt2bOuLlgqw6+po7f76Zldf6+/z+jveQD5/qK0Y1+zfQTvqH2p/J3q5Ir9HRUyKO5z/3xOHniA/HLgJeF9EXA0s2d3OmbkgMzszs3P06NHtrVSSpJIoYlJc9NGWmfkc8NG9XYwkSVVQRA+9Czii1/YYYHMzB4iIWRGxoLu7u6WFSZJUVkUE+gpgQkQcGRH7A+cBtzRzgMxckplzOzo62lKgJEll0+7b1q4FlgMTI6IrIi7MzB3AxcBtwDrg+sxc2+Rx7aFLktRLu2e5z95N+1Jg6SCOuwRY0tnZOWegx5AkqUp89KskSRVQykB3yF2SpHqlDHQnxUmSVK+UgS5JkuqVMtAdcpckqV4pA90hd0mS6kVmFl3DgEXEFuDXLTzkIcDvWni8ocBzKoeqnVPVzgc8p7Ko2jntej5vyMw+FzIpdaC3WkSszMzOoutoJc+pHKp2TlU7H/CcyqJq59TM+ZRyyF2SJNUz0CVJqgADvd6CogtoA8+pHKp2TlU7H/CcyqJq59Tw+XgNXZKkCrCHLklSBRjoNRExMyIeiYgNETGv6HoGKyIWRsSTEbGm6FpaISKOiIg7ImJdRKyNiE8VXdNgRcTIiLg/Ih6qndP/KLqmVomIYRHxYET8W9G1tEJEbIyIhyNidUSsLLqeVoiIgyLixohYX/t39ZaiaxqoiJhY+9689OfpiPh00XUNVkR8pvazYU1EXBsRI/f49Q659/zwAR4FzgS6gBXA7Mz8RaGFDUJEnAI8C3wnMycXXc9gRcShwKGZ+UBEvApYBbyn5N+jAA7MzGcjYgRwN/CpzLy34NIGLSI+C3QCr87MdxVdz2BFxEagMzMrc39zRPwLcFdmXhMR+wOjMvOpgssatNrP898CJ2RmK59TsldFxOH0/EyYlJnbIuJ6YGlmLtrdPvbQe8wANmTmY5m5HbgOOKfgmgYlM+8Efl90Ha2SmU9k5gO1188A64DDi61qcLLHs7XNEbU/pf8NOyLGAGcD1xRdi/oWEa8GTgG+BZCZ26sQ5jVnAL8qc5j3Mhx4RUQMB0YBm/f0xQZ6j8OBTb22uyh5WFRZRIwDpgP3FVzKoNWGplcDTwI/zczSnxPwD8DngRcLrqOVEvhJRKyKiLlFF9MCbwS2AN+uXRq5JiIOLLqoFjkPuLboIgYrM38LfA34DfAE0J2ZP9nTPgZ6j+ijrfQ9pSqKiFcCPwA+nZlPF13PYGXmC5k5DRgDzIiIUl8eiYh3AU9m5qqia2mxkzPzWOAs4OO1S1plNhw4Frg6M6cDzwFVmDu0P/Bu4IaiaxmsiHgNPSPFRwKHAQdGxAV72sdA79EFHNFrewz9DG1o76tdZ/4B8P3MvKnoelqpNty5DJhZbCWDdjLw7to15+uAt0XE94otafAyc3Ptv08CP6TnMl2ZdQFdvUaEbqQn4MvuLOCBzPzPogtpgbcDj2fmlsx8HrgJOGlPOxjoPVYAEyLiyNpveOcBtxRck3qpTSD7FrAuM79edD2tEBGjI+Kg2utX0PMPeH2hRQ1SZn4hM8dk5jh6/h3978zcY69iqIuIA2sTMakNS78DKPXdI5n5f4BNETGx1nQGUNoJpr3MpgLD7TW/AU6MiFG1n39n0DN3aLeG75WyhrjM3BERFwO3AcOAhZm5tuCyBiUirgVOAw6JiC7gK5n5rWKrGpSTgQ8DD9euOQN8MTOXFlfSoB0K/EttVu5+wPWZWYnbvCrmdcAPe36mMhz418z8cbEltcQngO/XOjGPAR8tuJ5BiYhR9Nyp9FdF19IKmXlfRNwIPADsAB6kn6fGeduaJEkV4JC7JEkVYKBLklQBBrokSRVgoEuSVAEGuiRJe0Gzi2ZFxAci4he1BVr+td+vd5a7JEnt18yiWRExAbgeeFtm/iEi/qz2YKPdsocuSdJe0NeiWRHx5xHx49o6AXdFxNG1t+YA8zPzD7V99xjmYKBLklSkBcAnMvM44HPAP9XajwKOioh7IuLeiOj3sdA+KU6SpALUFps6Cbih9iRCgANq/x0OTKDniZ9jgLsiYvKelrk10CVJKsZ+wFO1FRd31QXcW1uY5fGIeISegF+xp4NJkqS9rLYE9OMR8RfQswhVRBxTe/tHwOm19kPoGYJ/bE/HM9AlSdoLaotmLQcmRkRXRFwInA9cGBEPAWvpWQMdehYL2xoRvwDuAC7JzK17PL63rUmSVH720CVJqgADXZKkCjDQJUmqAANdkqQKMNAlSaoAA12SpAow0CVJqgADXZKkCvh/HRdmjbHMrJoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[[\"session_duration\"]].plot(kind=\"hist\", logy=True, bins=100, figsize=[8,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The rating is the session_duration scaled to be in the range 0-1.  This will help with training.\n",
    "median = stats.loc[\"50%\", \"session_duration\"]\n",
    "df[\"rating\"] = 0.3 * df[\"session_duration\"] / median\n",
    "df.loc[df[\"rating\"] > 1, \"rating\"] = 1\n",
    "df[[\"rating\"]].plot(kind=\"hist\", logy=True, bins=100, figsize=[8,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "del df[\"session_duration\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "rm -rf data\n",
    "mkdir data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df.to_csv(path_or_buf = \"data/collab_raw.csv\", index = False, header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1031539128969021923-1,299918857,0.24568213933399097\n",
      "1655026264169370690-165,299170525,0.15164102700829177\n",
      "1777072527276763113-113,299827911,0.03571599968005972\n",
      "1818199630884742957-45,299936493,0.22559522222518463\n",
      "2211768598185554204-465,255478055,0.831242168128616\n",
      "2695873766870665370-5,299587923,0.20680406324152825\n",
      "284119518435695096-1,299930675,1.0\n",
      "2869452701170253857-741,299693260,0.04747913722771749\n",
      "3010380941869544318-1441,299133651,0.027877462873596926\n",
      "3074506062059024768-18,299945076,0.19248673580931558\n"
     ]
    }
   ],
   "source": [
    "!head data/collab_raw.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Create dataset for WALS\n",
    "<p>\n",
    "The raw dataset (above) won't work for WALS:\n",
    "<ol>\n",
    "<li> The userId and itemId have to be 0,1,2 ... so we need to create a mapping from visitorId (in the raw data) to userId and contentId (in the raw data) to itemId.\n",
    "<li> We will need to save the above mapping to a file because at prediction time, we'll need to know how to map the contentId in the table above to the itemId.\n",
    "<li> We'll need two files: a \"rows\" dataset where all the items for a particular user are listed; and a \"columns\" dataset where all the users for a particular item are listed.\n",
    "</ol>\n",
    "\n",
    "<p>\n",
    "\n",
    "### Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "def create_mapping(values, filename):\n",
    "    with open(filename, 'w') as ofp:\n",
    "        value_to_id = {value:idx for idx, value in enumerate(values.unique())}\n",
    "        for value, idx in value_to_id.items():\n",
    "            ofp.write(\"{},{}\\n\".format(value, idx))\n",
    "    return value_to_id\n",
    "\n",
    "df = pd.read_csv(filepath_or_buffer = \"data/collab_raw.csv\",\n",
    "                 header = None,\n",
    "                 names = [\"visitorId\", \"contentId\", \"rating\"],\n",
    "                dtype = {\"visitorId\": str, \"contentId\": str, \"rating\": np.float})\n",
    "df.to_csv(path_or_buf = \"data/collab_raw.csv\", index = False, header = False)\n",
    "user_mapping = create_mapping(df[\"visitorId\"], \"data/users.csv\")\n",
    "item_mapping = create_mapping(df[\"contentId\"], \"data/items.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> data/collab_raw.csv <==\n",
      "1031539128969021923-1,299918857,0.2456821393339909\n",
      "1655026264169370690-165,299170525,0.1516410270082917\n",
      "1777072527276763113-113,299827911,0.0357159996800597\n",
      "\n",
      "==> data/items.csv <==\n",
      "299918857,0\n",
      "299170525,1\n",
      "299827911,2\n",
      "\n",
      "==> data/users.csv <==\n",
      "1031539128969021923-1,0\n",
      "1655026264169370690-165,1\n",
      "1777072527276763113-113,2\n"
     ]
    }
   ],
   "source": [
    "!head -3 data/*.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df[\"userId\"] = df[\"visitorId\"].map(user_mapping.get)\n",
    "df[\"itemId\"] = df[\"contentId\"].map(item_mapping.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>itemId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.245682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.151641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.035716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.225595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.831242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  itemId    rating\n",
       "0       0       0  0.245682\n",
       "1       1       1  0.151641\n",
       "2       2       2  0.035716\n",
       "3       3       3  0.225595\n",
       "4       4       4  0.831242"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapped_df = df[[\"userId\", \"itemId\", \"rating\"]]\n",
    "mapped_df.to_csv(path_or_buf = \"data/collab_mapped.csv\", index = False, header = False)\n",
    "mapped_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Creating rows and columns datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>itemId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.245682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.151641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.035716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.225595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.831242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  itemId    rating\n",
       "0       0       0  0.245682\n",
       "1       1       1  0.151641\n",
       "2       2       2  0.035716\n",
       "3       3       3  0.225595\n",
       "4       4       4  0.831242"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "mapped_df = pd.read_csv(filepath_or_buffer = \"data/collab_mapped.csv\", header = None, names = [\"userId\", \"itemId\", \"rating\"])\n",
    "mapped_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5670 items, 120869 users, 284302 interactions\n"
     ]
    }
   ],
   "source": [
    "NITEMS = np.max(mapped_df[\"itemId\"]) + 1\n",
    "NUSERS = np.max(mapped_df[\"userId\"]) + 1\n",
    "mapped_df[\"rating\"] = np.round(mapped_df[\"rating\"].values, 2)\n",
    "print(\"{} items, {} users, {} interactions\".format( NITEMS, NUSERS, len(mapped_df) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [    0   362   588 ... 11687 58106 14393] [0.25 1.   0.3  ... 0.2  0.6  0.36]\n",
      "1 [    1    30   249   351   800  1096  1285  1464  1472  1475  1750  1753\n",
      "  1959  2014  2018  2162  2229  2261  2274  2379  2467  2479  2522  2543\n",
      "  2699  2702  3255  3315  3393  3934  4134  4316  4621  4738  1963  5187\n",
      "  5431  5433  2299  5537  5548  5676  5780  5985  6132  6277  6386  6610\n",
      "  7075  7439  7508  7610  7631  7742  7749  7785  7827  8028  2009  8253\n",
      "  8311  8430  8435  8481  8563  8670  8710  8881  9063  9123  9521 10014\n",
      " 10069  1142 10569  7794 10783 11098 11216 11246  8547 11535 11629 11833\n",
      " 12099 12120 12199 12242 12473 12500 12522 12911 13119 13304  5034 13447\n",
      " 13738 13915 14251 14608 14609 14697 14709 15057 15200 15530 15531 15712\n",
      " 15823 15863 10753 15947 16076 16322 16505 16593  8923 16839 16934 17140\n",
      " 17214   492 17657 17779 17784 17811 17904  7870 18429 18510 18749 18755\n",
      " 18774 18908 19057 19193 19200 11721  9042  3042 19285 19300 19409 19494\n",
      " 19683 12394 19732 19814 19830 19843 19877   854  7080 20002 20148 20169\n",
      " 20390 20675 20801 20994 21160 21186 11434 21327 21354 21561 21630 21829\n",
      " 21866 21962 22003 22569 22810 22825 22831  5090 23014 23060 23131 23251\n",
      " 23411 11407 23490 16817 23777    65 23960  9431 24320 24324  6991 24435\n",
      " 24453 24515 24572 24787  7673 20530  5296 25230 20944 25504 25524 25614\n",
      " 25628 25810  6224 14559 19539  3793 26304 24275 19995  1082 26642 26676\n",
      " 26688 26712 26795 26823 18147 23013 27559 11637 16914 27937 27964  3360\n",
      "  3384  6800 28377 28427 28430 28520 28552 28632  4389 28808 28847 28886\n",
      "  4675 22693 29007 29053 29143 18555 29308 29340 29409  5527 29523 29668\n",
      " 14117 29796 19410 30039 23957 30192 30245   450  3761 30371 30394   841\n",
      " 30868 30871  7698 30958 30987 24965  1760  8017  8163 29514  5723 31600\n",
      " 31608 31699 31715 31726 31746 31779 14359 31869 31953 30075 32014 32022\n",
      " 32087 32183 30305 32254 32416 32470 32667 32718 28885 32816 32889 33007\n",
      " 33204  5472 33279 33319 33353 33364 33535 33629 33638 33794 33801 33829\n",
      " 33837 33865 34180 34440 34650 10526 28955 34774 34861 34925 34976 35278\n",
      " 35338 35398 35406 35446 31681 35529 35605   137 35740 32138 35904 17438\n",
      " 15129 36046 36054 36089 36106 32561 36274 36276 36385 36389 36450 24997\n",
      " 36717 36750 36760  8236 36885 11255 29630  6019 37321 37355 37357 37381\n",
      "   121 14668 37583 37639 37651 37692 37749 37822 37901 37995 38470  5243\n",
      " 38587 38612 38617 20962 38834 21286 38969 38999 39057 14409 35622 39149\n",
      "  3486 39391 39433 17368  3879 39521 32334 39532 12611 19900 39702 39713\n",
      " 39926 39928 39957 40181 40871  6502 40974 41091 41097 24206 41116 41268\n",
      " 41290 41543 10392 41580 41588 41616  4800 34736 41743 27047 41773 41838\n",
      " 41856 41960 27498  8496  2841 42380 23893  9416 42897 42920 42976 10159\n",
      " 38063 10366  4643 43244 43286 43315  1767 43547 43556 43864 43926 43990\n",
      " 19226 44024 14478 44095 44109 21681 44303 34249 44462 44762 22822 45007\n",
      " 45052 45146  5449 45258 31540 45398 45506 45543 29846 21437 45644 45899\n",
      " 19769 39499 24535 15350 44645 46280 46342 46582 46722 46835 11179  8464\n",
      " 46894 47052  6021 25868 47232 19569 33988  9760  9794 47644 47651 42973\n",
      " 22345 34502 47856 26818 47904 47944 28968  4988 48109 48141 48154 48248\n",
      " 48264 48320 48334  8615 37160 48588 48619 42367 42370 48732 48762 48796\n",
      " 48988 49089  1324 24816 10715 16198 49786 46973 14072 49983 50094 25957\n",
      " 30097 50279 50286  6700 14958   584 37687 50644 38082 44772 50859 38570\n",
      " 37005 51391 51435 51446 51714 17196 51764 30413 41206  9893  4505 52213\n",
      " 52320 10649  7998 52505 20862 52571  5570  8987 52896 52943 33773 25999\n",
      " 28225 53150 53334   964 53370 53413  1232 34594  7588 46387 53657  2686\n",
      " 35362 54263 35648 37411 54359 54424 54586 54728 39731 54781 15447 30751\n",
      " 54822  1295 47901 38343 51086 53939 55272 45362 14028 55466 55472 55477\n",
      " 42336 55492 55506 21490  3075  9152 29973 55622 26020 55693 55774 55796\n",
      " 55889 39555 56077 56224 36673 40220 56414 18712  5569 56753 56838 23790\n",
      " 39212 56993 19624  6692 57228  7048 57241 57258  4088 43128  1737 15877\n",
      " 57677 20883 33291 57889] [0.15 0.2  0.11 0.8  0.29 0.03 0.04 0.35 0.29 1.   1.   0.68 1.   0.21\n",
      " 1.   0.49 0.02 0.2  0.8  0.13 1.   0.07 0.11 0.89 1.   0.48 0.14 0.72\n",
      " 0.63 0.84 1.   1.   0.7  1.   0.75 1.   0.59 0.04 0.44 0.03 0.01 1.\n",
      " 0.92 1.   0.28 0.05 0.64 0.05 1.   0.36 0.61 0.91 0.78 0.95 0.8  0.06\n",
      " 0.03 0.42 1.   0.04 1.   1.   0.21 1.   0.38 0.73 1.   0.49 0.   1.\n",
      " 0.68 0.82 0.48 0.05 1.   1.   0.   0.23 0.72 0.7  0.01 1.   0.02 0.32\n",
      " 1.   0.81 1.   0.46 1.   0.65 0.04 0.   1.   1.   0.41 0.   0.54 0.36\n",
      " 0.01 0.9  0.57 0.22 0.05 0.79 1.   1.   0.61 0.   0.5  0.39 0.05 0.99\n",
      " 0.46 0.97 0.42 0.46 1.   0.44 1.   1.   0.76 0.05 1.   1.   1.   0.49\n",
      " 1.   0.07 0.   1.   0.   0.58 0.26 0.07 1.   0.13 0.69 0.65 0.14 0.1\n",
      " 1.   0.32 1.   0.46 0.17 0.63 1.   0.75 1.   0.08 0.63 0.56 0.57 0.68\n",
      " 0.17 1.   1.   1.   0.82 0.4  0.73 0.9  0.08 0.47 1.   1.   0.42 1.\n",
      " 1.   1.   0.06 1.   0.5  0.01 0.12 0.19 0.5  0.9  0.88 0.26 0.51 0.7\n",
      " 0.97 0.21 0.11 0.49 1.   0.01 0.01 0.85 1.   1.   0.06 1.   0.23 1.\n",
      " 0.01 0.05 0.21 1.   0.28 0.01 0.   0.6  0.46 0.93 0.28 0.06 0.73 0.69\n",
      " 1.   0.01 0.01 0.97 0.51 0.05 0.69 1.   0.73 0.87 1.   0.1  0.85 0.95\n",
      " 0.94 1.   0.41 0.02 0.3  0.47 0.   1.   0.   0.02 0.2  1.   0.59 0.\n",
      " 0.53 0.11 0.99 0.13 0.56 0.02 0.75 0.62 0.83 1.   0.69 1.   0.49 0.78\n",
      " 1.   0.04 0.1  0.08 0.5  0.88 0.79 0.43 0.36 1.   0.15 1.   0.04 1.\n",
      " 0.57 0.01 1.   0.42 0.42 0.01 0.   1.   0.45 1.   0.44 0.11 0.   1.\n",
      " 0.28 0.1  0.56 1.   0.03 0.04 1.   0.8  1.   0.41 0.93 1.   0.05 0.44\n",
      " 0.32 0.8  0.02 0.09 0.11 0.54 0.05 1.   0.   0.81 0.01 1.   1.   0.35\n",
      " 0.87 0.82 0.41 0.12 0.67 1.   0.51 0.14 0.73 1.   0.93 0.   1.   0.49\n",
      " 0.04 0.41 0.14 1.   0.   0.82 1.   0.02 0.44 0.9  0.58 0.02 0.19 0.77\n",
      " 0.47 0.02 1.   0.3  0.56 0.67 0.18 0.79 1.   0.1  0.29 0.13 0.26 0.22\n",
      " 1.   0.09 0.29 0.36 0.41 0.36 0.03 0.66 0.44 0.45 0.82 0.05 1.   0.66\n",
      " 1.   1.   0.2  0.64 0.63 0.   0.11 0.58 0.03 0.   0.36 0.44 0.61 0.8\n",
      " 0.69 0.86 0.84 0.92 0.01 0.04 1.   0.49 1.   0.56 0.96 0.04 0.35 0.47\n",
      " 0.04 0.04 0.13 0.45 1.   1.   0.44 0.04 0.1  0.83 1.   0.01 0.73 0.09\n",
      " 1.   0.57 1.   0.46 1.   0.01 1.   0.69 1.   1.   0.03 0.01 0.29 0.78\n",
      " 0.98 1.   0.8  0.1  0.88 0.72 0.04 0.7  1.   0.08 0.99 0.18 0.46 1.\n",
      " 1.   0.   0.14 1.   1.   0.6  1.   0.53 1.   0.74 0.61 0.06 1.   0.98\n",
      " 0.75 0.08 0.7  0.01 1.   0.05 0.09 0.26 1.   0.38 0.72 0.42 1.   0.03\n",
      " 1.   1.   0.83 1.   0.06 0.27 0.83 0.63 0.67 1.   0.51 0.82 0.63 0.\n",
      " 0.22 0.03 0.89 0.08 1.   1.   1.   0.14 0.18 0.14 0.39 0.08 1.   0.12\n",
      " 0.07 1.   1.   0.38 0.44 0.55 0.58 0.04 0.37 1.   0.97 0.2  1.   1.\n",
      " 1.   0.34 0.58 0.33 0.73 1.   0.04 0.05 1.   1.   0.38 0.08 0.14 0.\n",
      " 0.87 0.27 1.   0.21 1.   0.85 0.04 0.03 0.72 0.69 1.   0.12 0.63 0.03\n",
      " 0.02 0.69 0.03 0.65 0.08 0.02 1.   0.62 1.   0.72 0.12 0.2  0.79 0.52\n",
      " 0.29 0.05 0.65 0.62 0.01 1.   0.74 0.16 0.98 0.56 0.47 0.85 0.87 0.05\n",
      " 0.19 0.11 0.02 0.04 0.32 0.47 0.32 1.   0.98 1.   0.12 1.   0.2  1.\n",
      " 0.24 0.27 1.   0.75 0.26 0.04 0.01 0.   0.27 1.   0.24 0.04 0.49 0.47\n",
      " 0.04 0.33 0.63 0.14 0.51 0.91 0.09 1.   0.49 0.52 0.64 0.44 0.7  0.02\n",
      " 1.   0.1  0.03 0.27 1.   1.   1.   0.59 1.   0.7  0.03 0.09 0.54 1.\n",
      " 0.65 1.   0.12 0.   0.59 0.22 0.13 0.9  1.   0.74 1.   0.13 0.34 0.34\n",
      " 0.73 0.08 0.54 0.8  0.71 0.46 1.   0.02 0.25 0.49]\n",
      "2 [    2    45    51 ... 58072 31797 45666] [0.04 0.04 1.   ... 0.43 0.04 0.04]\n",
      "3 [    3   101   154   396   529   687   982  1059  1692  1693  1733  1909\n",
      "  2333  2383  2887  3072  3156  3414  3849  4005  4046  4210  4694  4736\n",
      "  5125  5326  5883  5992  6507   264  6735  7534  7934  7974  7982  7995\n",
      "  5154  8221  8367  8529  8589  8737  8806  8966  9364  9798 10253 10409\n",
      " 10552 10602 10790 10983 11010 11024 11219 11245 11278 11327 11441 11963\n",
      "  6352 12789  1039 12843 13329 13515 13604 13981 14061 14100 14210 14466\n",
      " 14578 14883   719 15238 16071 13838  9147 16976  3364 17311 17358   896\n",
      "  7480  7588 18234 18250 18264 18340 18353 18478 18519 19100 19178  6176\n",
      "   445 19736 19776 19818 19820 19935 20135  7516 20322 20450 13393  5133\n",
      " 20972 21024 21153 21170  5789  8707  8961  9115 21636 17624 10410 22598\n",
      " 20555 22927 22952 23256 11255  8861 23577 17310 24566 12922 23370  2584\n",
      " 25618 14165 14497 26046  9851 26501 12822 20152 26960 24893 27251 27276\n",
      " 27363 23163 27684 27791 27875 21783  6771  6961 22139  4096 26566  4452\n",
      " 24790 29019 29025 29107 18560 29386 29461 13944 29581 25538 29665  5808\n",
      " 11514 29727 29869 29924  6519   766 30539 30800  1595 18209 31198 31297\n",
      " 31485 31563 11913 31939 17075 32052 32444 32448 17776 32678 32765 32826\n",
      " 15779  7795 33005  1917 10920 20951 33274 33469 11821 33967 34106 17631\n",
      " 34519 34581 34598  4685 34649 16038 35057 35097 18995 14277 19237 35607\n",
      " 31943 35785 36095  4265 20182  4622 10607 36499 13374 31098 29496  5656\n",
      " 37046 23746 37374 37673 37713 36132 24605 15768 38306 38427 18590 35012\n",
      "  2384 21082 38737  5793 38931  6111 19361 39277 12220 39553 22134 39691\n",
      " 39987 40013 40144 40150 40153 13499 40239  2266 40399 40624 40632  6511\n",
      " 41246 12794 20130 41412 41464  1295 41529 41532 41552 41606 41658  7781\n",
      " 36531 31142 41964 42146 42211  5848 16642 42260 42300 42332 42521 42869\n",
      " 43017 26759 43199 26835 43261 43322 31100 43496 10902 43878 19093 43911\n",
      " 11699 43994 44015 19294 11889 44143 32269 15140 44464 44466  7382 44732\n",
      "  7614 44905 29203 31193 45089 45139 16362 45322 45324 29553 29579  5743\n",
      " 46183 10485 46623 36662  8108 46955 11563  8974 47196  3874 47566  1569\n",
      " 48075 27080 34832 33049 16043 22982 23083 48480 48486 48759 26073 17200\n",
      " 49065 49085 49099 49314 27003  2061 38532 49777 49919 45653  9607 10039\n",
      " 36111 42992 18649 51246 51281 51291 51372 45449 33496 51471 51767 19631\n",
      " 21935 51927 52036  1084 52289 52350 27318 52534 52623 52643 52648 45419\n",
      " 52750  2854 52978 53197 52205 26853 36409 53828 53850 48254 23110 21074\n",
      " 36946  2728 35443 52822 19581 54413 39439 54642 54645 54923 54945 55070\n",
      " 33058  8082 43580 33229 11328 33601 54385 37501  9604 42748 38287 13294\n",
      " 56306  5015 20929 56496 35115 56519 25396 33338 56630 54069 19224 33845\n",
      " 21931 36240 49308 26791 49351 18227 51059 38525 57715 40267 57753 57783\n",
      " 57799 36969 57945 21252 58004 33583 23829] [0.23 0.85 0.22 0.14 0.33 0.18 0.5  0.74 0.03 0.33 0.34 0.01 0.05 0.06\n",
      " 0.03 0.01 1.   0.26 0.46 0.64 0.29 0.12 0.02 0.37 0.23 1.   0.14 0.19\n",
      " 0.28 0.23 0.01 0.05 0.21 0.12 1.   0.09 0.01 0.3  0.14 0.02 0.94 0.27\n",
      " 0.6  0.22 0.3  0.06 0.96 0.05 0.15 0.12 0.94 0.77 0.79 0.22 0.32 0.39\n",
      " 0.12 0.46 0.   0.5  0.33 0.2  0.29 0.77 0.39 0.21 0.2  0.51 0.46 0.46\n",
      " 0.25 0.41 0.32 0.04 0.4  1.   0.16 0.32 0.03 0.18 0.46 0.12 0.12 0.24\n",
      " 0.37 0.18 0.08 0.02 0.11 0.29 0.01 0.22 0.01 0.14 0.5  0.   0.23 0.43\n",
      " 0.34 0.04 0.22 0.45 0.35 0.11 0.17 0.26 0.08 0.11 0.16 0.07 0.07 0.21\n",
      " 0.29 0.04 0.25 0.28 0.16 0.03 1.   0.02 0.11 1.   0.01 0.37 0.25 0.04\n",
      " 0.16 0.89 1.   0.01 0.58 0.01 0.16 0.35 0.04 0.04 0.04 0.17 0.39 0.21\n",
      " 0.17 0.07 0.04 0.03 0.44 0.81 0.29 0.01 0.49 0.2  0.14 0.22 0.08 0.27\n",
      " 0.41 0.23 0.06 0.19 0.14 0.34 0.75 0.56 0.01 0.05 0.17 0.5  0.15 0.02\n",
      " 0.2  0.35 0.31 0.21 0.35 0.23 0.19 0.33 0.02 0.6  0.3  0.35 0.   0.05\n",
      " 0.16 0.12 0.12 0.31 0.13 0.12 0.21 0.2  0.25 0.1  0.12 0.01 0.02 0.06\n",
      " 0.2  0.48 0.02 0.31 0.39 1.   1.   0.37 0.26 0.71 1.   0.64 0.25 0.33\n",
      " 0.44 0.2  0.05 0.04 0.08 0.11 0.44 0.31 0.28 0.02 0.13 0.42 0.15 1.\n",
      " 0.01 0.14 0.14 0.58 0.38 0.02 0.13 0.29 0.34 0.59 0.44 0.54 1.   0.24\n",
      " 0.09 0.67 0.15 0.33 0.63 0.24 0.06 0.33 0.04 0.1  0.38 0.46 0.06 0.25\n",
      " 0.13 0.42 0.21 0.32 0.35 0.27 0.29 0.12 0.22 0.4  1.   0.19 0.09 0.45\n",
      " 0.34 0.27 0.2  0.25 0.   0.25 0.19 0.01 0.36 0.12 0.04 1.   0.21 0.21\n",
      " 0.16 0.02 0.38 0.74 1.   1.   0.48 0.41 0.24 0.46 0.02 0.35 0.08 0.23\n",
      " 0.23 0.09 0.4  0.28 0.13 0.32 0.59 0.26 0.04 1.   0.34 0.61 0.68 0.21\n",
      " 0.24 0.45 0.68 0.39 0.32 1.   1.   0.13 1.   1.   0.62 1.   0.5  0.29\n",
      " 0.48 0.81 0.33 0.02 0.14 0.02 0.26 0.35 0.24 0.01 0.4  0.15 0.03 0.22\n",
      " 0.36 0.44 0.57 0.04 0.06 0.2  0.36 0.02 0.05 0.21 0.28 0.17 0.36 0.18\n",
      " 0.29 0.12 0.   0.36 0.89 0.02 0.11 1.   0.29 0.26 0.01 0.49 0.08 0.71\n",
      " 0.11 0.23 0.18 0.97 0.21 0.25 0.02 0.04 0.36 0.22 1.   0.35 0.02 0.03\n",
      " 1.   0.12 0.31 0.25 0.02 0.2  0.47 0.2  1.   1.   0.65 0.4  0.02 0.23\n",
      " 0.66 0.38 0.11 0.41 0.24 0.34 0.23 0.53 0.29 0.01 1.   0.24 0.3  0.14\n",
      " 0.54 0.59 0.49 0.07 0.59 0.15 0.32 1.   0.42 0.24 1.   0.01 1.   0.06\n",
      " 0.19 1.   0.03 0.25 0.38 0.67 0.1  0.21 0.19 0.23 0.03 0.52 0.08 1.\n",
      " 0.15 0.27 0.22 0.2  0.32 1.   0.06 0.18 0.03 0.03 0.23 0.41 1.   0.02\n",
      " 1.   0.69 0.43]\n",
      "4 [    4   742  3749  6584  7292  9301  7948 16278 18835 21612 27372 23267\n",
      " 32547  7575 34536 37748 18439 39951 41049 21244 45746  2083 18565 23386\n",
      " 47871 51257 19147  7920 52827 39576 15336 30929 11394] [0.83 0.37 0.41 1.   0.17 1.   0.74 0.28 0.14 0.41 0.43 0.03 0.71 1.\n",
      " 1.   1.   0.36 0.29 0.4  0.04 0.02 0.31 0.55 0.2  0.31 0.1  1.   1.\n",
      " 1.   0.04 0.21 1.   0.21]\n",
      "5 [    5  6437  6675  8790  9685 13124 14040 17498 29182 29584 30280 25783\n",
      " 32808 36938 36705 18344 47303 10529 50815 40573 10799 19449  4909 12740\n",
      " 43213] [0.21 0.05 0.69 0.44 0.82 0.01 1.   0.02 0.71 0.   0.06 0.04 0.01 0.25\n",
      " 0.28 0.5  0.03 0.22 0.   0.02 0.76 0.12 0.04 0.21 0.01]\n"
     ]
    }
   ],
   "source": [
    "grouped_by_items = mapped_df.groupby(\"itemId\")\n",
    "iter = 0\n",
    "for item, grouped in grouped_by_items:\n",
    "    print(item, grouped[\"userId\"].values, grouped[\"rating\"].values)\n",
    "    iter = iter + 1\n",
    "    if iter > 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_25848/1646577164.py:3: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "grouped_by_items = mapped_df.groupby(\"itemId\")\n",
    "with tf.python_io.TFRecordWriter(\"data/users_for_item\") as ofp:\n",
    "    for item, grouped in grouped_by_items:\n",
    "        example = tf.train.Example(features = tf.train.Features(feature = {\n",
    "            \"key\": tf.train.Feature(int64_list = tf.train.Int64List(value = [item])),\n",
    "            \"indices\": tf.train.Feature(int64_list = tf.train.Int64List(value = grouped[\"userId\"].values)),\n",
    "            \"values\": tf.train.Feature(float_list = tf.train.FloatList(value = grouped[\"rating\"].values))\n",
    "        }))\n",
    "        ofp.write(example.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "grouped_by_users = mapped_df.groupby(\"userId\")\n",
    "with tf.python_io.TFRecordWriter(\"data/items_for_user\") as ofp:\n",
    "    for user, grouped in grouped_by_users:\n",
    "        example = tf.train.Example(features = tf.train.Features(feature = {\n",
    "            \"key\": tf.train.Feature(int64_list = tf.train.Int64List(value = [user])),\n",
    "            \"indices\": tf.train.Feature(int64_list = tf.train.Int64List(value = grouped[\"itemId\"].values)),\n",
    "            \"values\": tf.train.Feature(float_list = tf.train.FloatList(value = grouped[\"rating\"].values))\n",
    "        }))\n",
    "        ofp.write(example.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 36552\n",
      "-rw-r--r-- 1 jupyter jupyter 14121616 Nov  8 15:03 collab_raw.csv\n",
      "-rw-r--r-- 1 jupyter jupyter  3525697 Nov  8 15:03 users.csv\n",
      "-rw-r--r-- 1 jupyter jupyter    82217 Nov  8 15:03 items.csv\n",
      "-rw-r--r-- 1 jupyter jupyter  7661290 Nov  8 15:03 collab_mapped.csv\n",
      "-rw-r--r-- 1 jupyter jupyter  2296744 Nov  8 15:03 users_for_item\n",
      "-rw-r--r-- 1 jupyter jupyter  9728585 Nov  8 15:03 items_for_user\n"
     ]
    }
   ],
   "source": [
    "!ls -lrt data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "To summarize, we created the following data files from collab_raw.csv:\n",
    "<ol>\n",
    "<li> ```collab_mapped.csv``` is essentially the same data as in ```collab_raw.csv``` except that ```visitorId``` and ```contentId``` which are business-specific have been mapped to ```userId``` and ```itemId``` which are enumerated in 0,1,2,....  The mappings themselves are stored in ```items.csv``` and ```users.csv``` so that they can be used during inference.\n",
    "<li> ```users_for_item``` contains all the users/ratings for each item in TFExample format\n",
    "<li> ```items_for_user``` contains all the items/ratings for each user in TFExample format\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Train with WALS\n",
    "\n",
    "Once you have the dataset, do matrix factorization with WALS using the [WALSMatrixFactorization](https://www.tensorflow.org/versions/master/api_docs/python/tf/contrib/factorization/WALSMatrixFactorization) in the contrib directory.\n",
    "This is an estimator model, so it should be relatively familiar.\n",
    "<p>\n",
    "As usual, we write an input_fn to provide the data to the model, and then create the Estimator to do train_and_evaluate.\n",
    "Because it is in contrib and hasn't moved over to tf.estimator yet, we use tf.contrib.learn.Experiment to handle the training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.lib.io import file_io\n",
    "from tensorflow.contrib.factorization import WALSMatrixFactorization\n",
    "  \n",
    "def read_dataset(mode, args):\n",
    "    def decode_example(protos, vocab_size):\n",
    "        features = {\n",
    "            \"key\": tf.FixedLenFeature(shape = [1], dtype = tf.int64),\n",
    "            \"indices\": tf.VarLenFeature(dtype = tf.int64),\n",
    "            \"values\": tf.VarLenFeature(dtype = tf.float32)}\n",
    "        parsed_features = tf.parse_single_example(serialized = protos, features = features)\n",
    "        values = tf.sparse_merge(sp_ids = parsed_features[\"indices\"], sp_values = parsed_features[\"values\"], vocab_size = vocab_size)\n",
    "        # Save key to remap after batching\n",
    "        # This is a temporary workaround to assign correct row numbers in each batch.\n",
    "        # You can ignore details of this part and remap_keys().\n",
    "        key = parsed_features[\"key\"]\n",
    "        decoded_sparse_tensor = tf.SparseTensor(indices = tf.concat(values = [values.indices, [key]], axis = 0), \n",
    "                                                values = tf.concat(values = [values.values, [0.0]], axis = 0), \n",
    "                                                dense_shape = values.dense_shape)\n",
    "        return decoded_sparse_tensor\n",
    "  \n",
    "  \n",
    "    def remap_keys(sparse_tensor):\n",
    "        # Current indices of our SparseTensor that we need to fix\n",
    "        bad_indices = sparse_tensor.indices # shape = (current_batch_size * (number_of_items/users[i] + 1), 2)\n",
    "        # Current values of our SparseTensor that we need to fix\n",
    "        bad_values = sparse_tensor.values # shape = (current_batch_size * (number_of_items/users[i] + 1),)\n",
    "\n",
    "        # Since batch is ordered, the last value for a batch index is the user\n",
    "        # Find where the batch index chages to extract the user rows\n",
    "        # 1 where user, else 0\n",
    "        user_mask = tf.concat(values = [bad_indices[1:,0] - bad_indices[:-1,0], tf.constant(value = [1], dtype = tf.int64)], axis = 0) # shape = (current_batch_size * (number_of_items/users[i] + 1), 2)\n",
    "\n",
    "        # Mask out the user rows from the values\n",
    "        good_values = tf.boolean_mask(tensor = bad_values, mask = tf.equal(x = user_mask, y = 0)) # shape = (current_batch_size * number_of_items/users[i],)\n",
    "        item_indices = tf.boolean_mask(tensor = bad_indices, mask = tf.equal(x = user_mask, y = 0)) # shape = (current_batch_size * number_of_items/users[i],)\n",
    "        user_indices = tf.boolean_mask(tensor = bad_indices, mask = tf.equal(x = user_mask, y = 1))[:, 1] # shape = (current_batch_size,)\n",
    "\n",
    "        good_user_indices = tf.gather(params = user_indices, indices = item_indices[:,0]) # shape = (current_batch_size * number_of_items/users[i],)\n",
    "\n",
    "        # User and item indices are rank 1, need to make rank 1 to concat\n",
    "        good_user_indices_expanded = tf.expand_dims(input = good_user_indices, axis = -1) # shape = (current_batch_size * number_of_items/users[i], 1)\n",
    "        good_item_indices_expanded = tf.expand_dims(input = item_indices[:, 1], axis = -1) # shape = (current_batch_size * number_of_items/users[i], 1)\n",
    "        good_indices = tf.concat(values = [good_user_indices_expanded, good_item_indices_expanded], axis = 1) # shape = (current_batch_size * number_of_items/users[i], 2)\n",
    "\n",
    "        remapped_sparse_tensor = tf.SparseTensor(indices = good_indices, values = good_values, dense_shape = sparse_tensor.dense_shape)\n",
    "        return remapped_sparse_tensor\n",
    "\n",
    "    \n",
    "    def parse_tfrecords(filename, vocab_size):\n",
    "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            num_epochs = None # indefinitely\n",
    "        else:\n",
    "            num_epochs = 1 # end-of-input after this\n",
    "\n",
    "        files = tf.gfile.Glob(filename = os.path.join(args[\"input_path\"], filename))\n",
    "\n",
    "        # Create dataset from file list\n",
    "        dataset = tf.data.TFRecordDataset(files)\n",
    "        dataset = dataset.map(map_func = lambda x: decode_example(x, vocab_size))\n",
    "        dataset = dataset.repeat(count = num_epochs)\n",
    "        dataset = dataset.batch(batch_size = args[\"batch_size\"])\n",
    "        dataset = dataset.map(map_func = lambda x: remap_keys(x))\n",
    "        return dataset.make_one_shot_iterator().get_next()\n",
    "  \n",
    "    def _input_fn():\n",
    "        features = {\n",
    "            WALSMatrixFactorization.INPUT_ROWS: parse_tfrecords(\"items_for_user\", args[\"nitems\"]),\n",
    "            WALSMatrixFactorization.INPUT_COLS: parse_tfrecords(\"users_for_item\", args[\"nusers\"]),\n",
    "            WALSMatrixFactorization.PROJECT_ROW: tf.constant(True)\n",
    "        }\n",
    "        return features, None\n",
    "\n",
    "    return _input_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This code is helpful in developing the input function. You don't need it in production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseTensorValue(indices=array([[   0,    0],\n",
      "       [   0,   95],\n",
      "       [   0, 5626],\n",
      "       [   0, 5632],\n",
      "       [   0, 5644],\n",
      "       [   0, 5647],\n",
      "       [   0, 5653],\n",
      "       [   1,    1],\n",
      "       [   1,  100],\n",
      "       [   1,  144],\n",
      "       [   1,  978],\n",
      "       [   1, 5635],\n",
      "       [   2,    2],\n",
      "       [   2,   32],\n",
      "       [   2,  893],\n",
      "       [   2, 1614],\n",
      "       [   2, 2649],\n",
      "       [   2, 5630],\n",
      "       [   2, 5632],\n",
      "       [   3,    3],\n",
      "       [   3,   58],\n",
      "       [   3, 5664],\n",
      "       [   3, 5669]]), values=array([0.25, 0.36, 0.04, 1.  , 0.07, 0.32, 0.03, 0.15, 0.06, 0.48, 0.13,\n",
      "       0.83, 0.04, 0.03, 0.05, 0.02, 0.02, 0.02, 0.13, 0.23, 0.28, 0.13,\n",
      "       0.76], dtype=float32), dense_shape=array([   4, 5670]))\n",
      "SparseTensorValue(indices=array([[   4,    4],\n",
      "       [   4,  136],\n",
      "       [   4,  168],\n",
      "       [   4,  469],\n",
      "       [   4, 5620],\n",
      "       [   4, 5629],\n",
      "       [   4, 5650],\n",
      "       [   4, 5656],\n",
      "       [   5,    5],\n",
      "       [   5,   91],\n",
      "       [   5,  178],\n",
      "       [   5, 5624],\n",
      "       [   5, 5628],\n",
      "       [   5, 5631],\n",
      "       [   5, 5633],\n",
      "       [   5, 5637],\n",
      "       [   5, 5642],\n",
      "       [   5, 5643],\n",
      "       [   5, 5645],\n",
      "       [   5, 5646],\n",
      "       [   5, 5648],\n",
      "       [   5, 5654],\n",
      "       [   6,    6],\n",
      "       [   6,   44],\n",
      "       [   6,  155],\n",
      "       [   6,  179],\n",
      "       [   6,  423],\n",
      "       [   6,  678],\n",
      "       [   6, 1091],\n",
      "       [   6, 1654],\n",
      "       [   6, 2722],\n",
      "       [   6, 5645],\n",
      "       [   6, 5646],\n",
      "       [   6, 5652],\n",
      "       [   6, 5655],\n",
      "       [   7,    7],\n",
      "       [   7, 5634]]), values=array([0.83, 1.  , 0.82, 1.  , 0.27, 0.64, 0.28, 0.99, 0.21, 0.23, 0.33,\n",
      "       0.23, 1.  , 0.41, 0.87, 0.92, 0.42, 0.24, 0.29, 1.  , 0.51, 0.69,\n",
      "       1.  , 1.  , 0.6 , 0.32, 1.  , 1.  , 0.35, 0.25, 1.  , 0.2 , 1.  ,\n",
      "       0.37, 0.71, 0.05, 0.  ], dtype=float32), dense_shape=array([   4, 5670]))\n"
     ]
    }
   ],
   "source": [
    "def try_out():\n",
    "    with tf.Session() as sess:\n",
    "        fn = read_dataset(\n",
    "            mode = tf.estimator.ModeKeys.EVAL, \n",
    "            args = {\"input_path\": \"data\", \"batch_size\": 4, \"nitems\": NITEMS, \"nusers\": NUSERS})\n",
    "        feats, _ = fn()\n",
    "        \n",
    "        print(feats[\"input_rows\"].eval())\n",
    "        print(feats[\"input_rows\"].eval())\n",
    "\n",
    "try_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def find_top_k(user, item_factors, k):\n",
    "    all_items = tf.matmul(a = tf.expand_dims(input = user, axis = 0), b = tf.transpose(a = item_factors))\n",
    "    topk = tf.nn.top_k(input = all_items, k = k)\n",
    "    return tf.cast(x = topk.indices, dtype = tf.int64)\n",
    "    \n",
    "def batch_predict(args):\n",
    "    import numpy as np\n",
    "    with tf.Session() as sess:\n",
    "        estimator = tf.contrib.factorization.WALSMatrixFactorization(\n",
    "            num_rows = args[\"nusers\"], \n",
    "            num_cols = args[\"nitems\"],\n",
    "            embedding_dimension = args[\"n_embeds\"],\n",
    "            model_dir = args[\"output_dir\"])\n",
    "        \n",
    "        # This is how you would get the row factors for out-of-vocab user data\n",
    "        # row_factors = list(estimator.get_projections(input_fn=read_dataset(tf.estimator.ModeKeys.EVAL, args)))\n",
    "        # user_factors = tf.convert_to_tensor(np.array(row_factors))\n",
    "\n",
    "        # But for in-vocab data, the row factors are already in the checkpoint\n",
    "        user_factors = tf.convert_to_tensor(value = estimator.get_row_factors()[0]) # (nusers, nembeds)\n",
    "        # In either case, we have to assume catalog doesn\"t change, so col_factors are read in\n",
    "        item_factors = tf.convert_to_tensor(value = estimator.get_col_factors()[0])# (nitems, nembeds)\n",
    "\n",
    "        # For each user, find the top K items\n",
    "        topk = tf.squeeze(input = tf.map_fn(fn = lambda user: find_top_k(user, item_factors, args[\"topk\"]), elems = user_factors, dtype = tf.int64))\n",
    "        with file_io.FileIO(os.path.join(args[\"output_dir\"], \"batch_pred.txt\"), mode = 'w') as f:\n",
    "            for best_items_for_user in topk.eval():\n",
    "                f.write(\",\".join(str(x) for x in best_items_for_user) + '\\n')\n",
    "\n",
    "def train_and_evaluate(args):\n",
    "    train_steps = int(0.5 + (1.0 * args[\"num_epochs\"] * args[\"nusers\"]) / args[\"batch_size\"])\n",
    "    steps_in_epoch = int(0.5 + args[\"nusers\"] / args[\"batch_size\"])\n",
    "    print(\"Will train for {} steps, evaluating once every {} steps\".format(train_steps, steps_in_epoch))\n",
    "    def experiment_fn(output_dir):\n",
    "        return tf.contrib.learn.Experiment(\n",
    "            tf.contrib.factorization.WALSMatrixFactorization(\n",
    "                num_rows = args[\"nusers\"], \n",
    "                num_cols = args[\"nitems\"],\n",
    "                embedding_dimension = args[\"n_embeds\"],\n",
    "                model_dir = args[\"output_dir\"]),\n",
    "            train_input_fn = read_dataset(tf.estimator.ModeKeys.TRAIN, args),\n",
    "            eval_input_fn = read_dataset(tf.estimator.ModeKeys.EVAL, args),\n",
    "            train_steps = train_steps,\n",
    "            eval_steps = 1,\n",
    "            min_eval_frequency = steps_in_epoch\n",
    "        )\n",
    "\n",
    "    from tensorflow.contrib.learn.python.learn import learn_runner\n",
    "    learn_runner.run(experiment_fn = experiment_fn, output_dir = args[\"output_dir\"])\n",
    "    \n",
    "    batch_predict(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will train for 12 steps, evaluating once every 236 steps\n",
      "WARNING:tensorflow:From /tmp/ipykernel_25848/1819520735.py:49: run (from tensorflow.contrib.learn.python.learn.learn_runner) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.estimator.train_and_evaluate.\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/contrib/learn/python/learn/estimators/estimator.py:1180: BaseEstimator.__init__ (from tensorflow.contrib.learn.python.learn.estimators.estimator) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please replace uses of any Estimator from tf.contrib.learn with an Estimator from tf.estimator.*\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/contrib/learn/python/learn/estimators/estimator.py:427: RunConfig.__init__ (from tensorflow.contrib.learn.python.learn.estimators.run_config) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "When switching to tf.estimator.Estimator, use tf.estimator.RunConfig instead.\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fef980e4a90>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': 'wals_trained', '_session_creation_timeout_secs': 7200}\n",
      "WARNING:tensorflow:From /tmp/ipykernel_25848/1819520735.py:45: Experiment.__init__ (from tensorflow.contrib.learn.python.learn.experiment) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.estimator.train_and_evaluate. You will also have to convert to a tf.estimator.Estimator.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/contrib/learn/python/learn/monitors.py:279: BaseMonitor.__init__ (from tensorflow.contrib.learn.python.learn.monitors) is deprecated and will be removed after 2016-12-05.\n",
      "Instructions for updating:\n",
      "Monitors are deprecated. Please use tf.train.SessionRunHook.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/contrib/factorization/python/ops/wals.py:315: ModelFnOps.__new__ (from tensorflow.contrib.learn.python.learn.estimators.model_fn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "When switching to tf.estimator.Estimator, use tf.estimator.EstimatorSpec. You can use the `estimator_spec` method to create an equivalent one.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into wals_trained/model.ckpt.\n",
      "INFO:tensorflow:SweepHook running init op.\n",
      "INFO:tensorflow:SweepHook running prep ops for the row sweep.\n",
      "INFO:tensorflow:Next fit step starting.\n",
      "INFO:tensorflow:loss = 188015.6, step = 1\n",
      "INFO:tensorflow:Next fit step starting.\n",
      "INFO:tensorflow:Next fit step starting.\n",
      "INFO:tensorflow:Next fit step starting.\n",
      "INFO:tensorflow:Next fit step starting.\n",
      "INFO:tensorflow:Next fit step starting.\n",
      "INFO:tensorflow:Next fit step starting.\n",
      "INFO:tensorflow:Next fit step starting.\n",
      "INFO:tensorflow:Next fit step starting.\n",
      "INFO:tensorflow:Next fit step starting.\n",
      "INFO:tensorflow:Next fit step starting.\n",
      "INFO:tensorflow:Next fit step starting.\n",
      "INFO:tensorflow:Saving checkpoints for 12 into wals_trained/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 171757.6.\n",
      "INFO:tensorflow:Starting evaluation at 2021-11-08T15:05:26Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from wals_trained/model.ckpt-12\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2021-11-08-15:05:27\n",
      "INFO:tensorflow:Saving dict for global step 12: global_step = 12, loss = 188015.6\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fef89b21fd0>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': 'wals_trained', '_session_creation_timeout_secs': 7200}\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "shutil.rmtree(path = \"wals_trained\", ignore_errors=True)\n",
    "train_and_evaluate({\n",
    "    \"output_dir\": \"wals_trained\",\n",
    "    \"input_path\": \"data/\",\n",
    "    \"num_epochs\": 0.05,\n",
    "    \"nitems\": NITEMS,\n",
    "    \"nusers\": NUSERS,\n",
    "\n",
    "    \"batch_size\": 512,\n",
    "    \"n_embeds\": 10,\n",
    "    \"topk\": 3\n",
    "  })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_pred.txt\n",
      "checkpoint\n",
      "eval\n",
      "events.out.tfevents.1636383923.tensorflow-1-15-20211108-104507\n",
      "graph.pbtxt\n",
      "model.ckpt-0.data-00000-of-00001\n",
      "model.ckpt-0.index\n",
      "model.ckpt-0.meta\n",
      "model.ckpt-12.data-00000-of-00001\n",
      "model.ckpt-12.index\n",
      "model.ckpt-12.meta\n"
     ]
    }
   ],
   "source": [
    "!ls wals_trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632,1458,3023\n",
      "3785,4847,1061\n",
      "2838,5179,3959\n",
      "3378,1412,447\n",
      "4065,1948,1882\n",
      "1038,5581,5447\n",
      "2764,2005,4180\n",
      "574,5607,725\n",
      "3023,3225,388\n",
      "2246,3364,574\n"
     ]
    }
   ],
   "source": [
    "!head wals_trained/batch_pred.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Run as a Python module\n",
    "\n",
    "Let's run it as Python module for just a few steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"NITEMS\"] = str(NITEMS)\n",
    "os.environ[\"NUSERS\"] = str(NUSERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will train for 2 steps, evaluating once every 236 steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jupyter/training-data-analyst/courses/machine_learning/deepdive/10_recommend/walsmodel/model.py:27: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/training-data-analyst/courses/machine_learning/deepdive/10_recommend/walsmodel/model.py:27: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/training-data-analyst/courses/machine_learning/deepdive/10_recommend/walsmodel/model.py:163: run (from tensorflow.contrib.learn.python.learn.learn_runner) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.estimator.train_and_evaluate.\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/contrib/learn/python/learn/estimators/estimator.py:1180: BaseEstimator.__init__ (from tensorflow.contrib.learn.python.learn.estimators.estimator) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please replace uses of any Estimator from tf.contrib.learn with an Estimator from tf.estimator.*\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/contrib/learn/python/learn/estimators/estimator.py:427: RunConfig.__init__ (from tensorflow.contrib.learn.python.learn.estimators.run_config) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "When switching to tf.estimator.Estimator, use tf.estimator.RunConfig instead.\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f4d8fbcb910>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'cloud', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/home/jupyter/training-data-analyst/courses/machine_learning/deepdive/10_recommend/wals_trained/', '_session_creation_timeout_secs': 7200}\n",
      "WARNING:tensorflow:From /home/jupyter/training-data-analyst/courses/machine_learning/deepdive/10_recommend/walsmodel/model.py:159: Experiment.__init__ (from tensorflow.contrib.learn.python.learn.experiment) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.estimator.train_and_evaluate. You will also have to convert to a tf.estimator.Estimator.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/contrib/learn/python/learn/monitors.py:279: BaseMonitor.__init__ (from tensorflow.contrib.learn.python.learn.monitors) is deprecated and will be removed after 2016-12-05.\n",
      "Instructions for updating:\n",
      "Monitors are deprecated. Please use tf.train.SessionRunHook.\n",
      "WARNING:tensorflow:From /home/jupyter/training-data-analyst/courses/machine_learning/deepdive/10_recommend/walsmodel/model.py:90: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.VarLenFeature is deprecated. Please use tf.io.VarLenFeature instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/training-data-analyst/courses/machine_learning/deepdive/10_recommend/walsmodel/model.py:46: sparse_merge (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "No similar op available at this time.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/ops/array_ops.py:1475: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/jupyter/training-data-analyst/courses/machine_learning/deepdive/10_recommend/walsmodel/model.py:98: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/contrib/factorization/python/ops/wals.py:315: ModelFnOps.__new__ (from tensorflow.contrib.learn.python.learn.estimators.model_fn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "When switching to tf.estimator.Estimator, use tf.estimator.EstimatorSpec. You can use the `estimator_spec` method to create an equivalent one.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "2021-11-08 15:05:47.219643: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200160000 Hz\n",
      "2021-11-08 15:05:47.220080: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55e8f74da580 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-11-08 15:05:47.220145: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2021-11-08 15:05:47.220300: I tensorflow/core/common_runtime/process_util.cc:136] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /home/jupyter/training-data-analyst/courses/machine_learning/deepdive/10_recommend/wals_trained/model.ckpt.\n",
      "INFO:tensorflow:SweepHook running init op.\n",
      "INFO:tensorflow:SweepHook running prep ops for the row sweep.\n",
      "INFO:tensorflow:Next fit step starting.\n",
      "INFO:tensorflow:loss = 187902.4, step = 1\n",
      "INFO:tensorflow:Next fit step starting.\n",
      "INFO:tensorflow:Saving checkpoints for 2 into /home/jupyter/training-data-analyst/courses/machine_learning/deepdive/10_recommend/wals_trained/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 181397.06.\n",
      "INFO:tensorflow:Starting evaluation at 2021-11-08T15:05:49Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /home/jupyter/training-data-analyst/courses/machine_learning/deepdive/10_recommend/wals_trained/model.ckpt-2\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2021-11-08-15:05:50\n",
      "INFO:tensorflow:Saving dict for global step 2: global_step = 2, loss = 187902.4\n",
      "WARNING:tensorflow:From /home/jupyter/training-data-analyst/courses/machine_learning/deepdive/10_recommend/walsmodel/model.py:122: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f4dd8db5410>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'cloud', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/home/jupyter/training-data-analyst/courses/machine_learning/deepdive/10_recommend/wals_trained/', '_session_creation_timeout_secs': 7200}\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "rm -rf wals.tar.gz wals_trained\n",
    "gcloud ai-platform local train \\\n",
    "    --module-name=walsmodel.task \\\n",
    "    --package-path=${PWD}/walsmodel \\\n",
    "    -- \\\n",
    "    --output_dir=${PWD}/wals_trained \\\n",
    "    --input_path=${PWD}/data \\\n",
    "    --num_epochs=0.01 --nitems=${NITEMS} --nusers=${NUSERS} \\\n",
    "    --job-dir=./tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Run on Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying file://data/collab_mapped.csv [Content-Type=text/csv]...\n",
      "Copying file://data/collab_raw.csv [Content-Type=text/csv]...\n",
      "Copying file://data/items.csv [Content-Type=text/csv]...\n",
      "Copying file://data/users_for_item [Content-Type=application/octet-stream]...\n",
      "Copying file://data/users.csv [Content-Type=text/csv]...\n",
      "Copying file://data/items_for_user [Content-Type=application/octet-stream]...\n",
      "- [6/6 files][ 35.7 MiB/ 35.7 MiB] 100% Done                                    \n",
      "Operation completed over 6 objects/35.7 MiB.                                     \n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gsutil -m cp data/* gs://${BUCKET}/wals/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://qwiklabs-gcp-03-2787a45a1534/wals/model_trained us-central1 wals_211108_150600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CommandException: 1 files/objects could not be removed.\n",
      "ERROR: (gcloud.ai-platform.jobs.submit.training) FAILED_PRECONDITION: Field: job_dir Error: The provided GCS path gs://qwiklabs-gcp-03-2787a45a1534/wals/model_trained cannot be written by service account service-243818477912@cloud-ml.google.com.iam.gserviceaccount.com.\n",
      "- '@type': type.googleapis.com/google.rpc.BadRequest\n",
      "  fieldViolations:\n",
      "  - description: The provided GCS path gs://qwiklabs-gcp-03-2787a45a1534/wals/model_trained\n",
      "      cannot be written by service account service-243818477912@cloud-ml.google.com.iam.gserviceaccount.com.\n",
      "    field: job_dir\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'b'OUTDIR=gs://${BUCKET}/wals/model_trained\\nJOBNAME=wals_$(date -u +%y%m%d_%H%M%S)\\necho $OUTDIR $REGION $JOBNAME\\ngsutil -m rm -rf $OUTDIR\\ngcloud ai-platform jobs submit training $JOBNAME \\\\\\n    --region=$REGION \\\\\\n    --module-name=walsmodel.task \\\\\\n    --package-path=${PWD}/walsmodel \\\\\\n    --job-dir=$OUTDIR \\\\\\n    --staging-bucket=gs://$BUCKET \\\\\\n    --scale-tier=BASIC_GPU \\\\\\n    --runtime-version=$TFVERSION \\\\\\n    -- \\\\\\n    --output_dir=$OUTDIR \\\\\\n    --input_path=gs://${BUCKET}/wals/data \\\\\\n    --num_epochs=10 --nitems=${NITEMS} --nusers=${NUSERS} \\n'' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_25848/158902532.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bash'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'OUTDIR=gs://${BUCKET}/wals/model_trained\\nJOBNAME=wals_$(date -u +%y%m%d_%H%M%S)\\necho $OUTDIR $REGION $JOBNAME\\ngsutil -m rm -rf $OUTDIR\\ngcloud ai-platform jobs submit training $JOBNAME \\\\\\n    --region=$REGION \\\\\\n    --module-name=walsmodel.task \\\\\\n    --package-path=${PWD}/walsmodel \\\\\\n    --job-dir=$OUTDIR \\\\\\n    --staging-bucket=gs://$BUCKET \\\\\\n    --scale-tier=BASIC_GPU \\\\\\n    --runtime-version=$TFVERSION \\\\\\n    -- \\\\\\n    --output_dir=$OUTDIR \\\\\\n    --input_path=gs://${BUCKET}/wals/data \\\\\\n    --num_epochs=10 --nitems=${NITEMS} --nusers=${NUSERS} \\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2404\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2405\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2406\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2407\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mnamed_script_magic\u001b[0;34m(line, cell)\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscript\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshebang\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;31m# write a basic docstring:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/decorator.py\u001b[0m in \u001b[0;36mfun\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mkwsyntax\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcaller\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextras\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m     \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_error\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mCalledProcessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_script\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_close\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command 'b'OUTDIR=gs://${BUCKET}/wals/model_trained\\nJOBNAME=wals_$(date -u +%y%m%d_%H%M%S)\\necho $OUTDIR $REGION $JOBNAME\\ngsutil -m rm -rf $OUTDIR\\ngcloud ai-platform jobs submit training $JOBNAME \\\\\\n    --region=$REGION \\\\\\n    --module-name=walsmodel.task \\\\\\n    --package-path=${PWD}/walsmodel \\\\\\n    --job-dir=$OUTDIR \\\\\\n    --staging-bucket=gs://$BUCKET \\\\\\n    --scale-tier=BASIC_GPU \\\\\\n    --runtime-version=$TFVERSION \\\\\\n    -- \\\\\\n    --output_dir=$OUTDIR \\\\\\n    --input_path=gs://${BUCKET}/wals/data \\\\\\n    --num_epochs=10 --nitems=${NITEMS} --nusers=${NUSERS} \\n'' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "OUTDIR=gs://${BUCKET}/wals/model_trained\n",
    "JOBNAME=wals_$(date -u +%y%m%d_%H%M%S)\n",
    "echo $OUTDIR $REGION $JOBNAME\n",
    "gsutil -m rm -rf $OUTDIR\n",
    "gcloud ai-platform jobs submit training $JOBNAME \\\n",
    "    --region=$REGION \\\n",
    "    --module-name=walsmodel.task \\\n",
    "    --package-path=${PWD}/walsmodel \\\n",
    "    --job-dir=$OUTDIR \\\n",
    "    --staging-bucket=gs://$BUCKET \\\n",
    "    --scale-tier=BASIC_GPU \\\n",
    "    --runtime-version=$TFVERSION \\\n",
    "    -- \\\n",
    "    --output_dir=$OUTDIR \\\n",
    "    --input_path=gs://${BUCKET}/wals/data \\\n",
    "    --num_epochs=10 --nitems=${NITEMS} --nusers=${NUSERS} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This took <b>10 minutes</b> for me."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get row and column factors\n",
    "\n",
    "Once you have a trained WALS model, you can get row and column factors (user and item embeddings) from the checkpoint file. We'll look at how to use these in the section on building a recommendation system using deep neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_factors(args):\n",
    "    with tf.Session() as sess:\n",
    "        estimator = tf.contrib.factorization.WALSMatrixFactorization(\n",
    "            num_rows = args[\"nusers\"], \n",
    "            num_cols = args[\"nitems\"],\n",
    "            embedding_dimension = args[\"n_embeds\"],\n",
    "            model_dir = args[\"output_dir\"])\n",
    "        \n",
    "        row_factors = estimator.get_row_factors()[0]\n",
    "        col_factors = estimator.get_col_factors()[0]\n",
    "    return row_factors, col_factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"output_dir\": \"gs://{}/wals/model_trained\".format(BUCKET),\n",
    "    \"nitems\": NITEMS,\n",
    "    \"nusers\": NUSERS,\n",
    "    \"n_embeds\": 10\n",
    "  }\n",
    "\n",
    "user_embeddings, item_embeddings = get_factors(args)\n",
    "print(user_embeddings[:3])\n",
    "print(item_embeddings[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can visualize the embedding vectors using dimensional reduction techniques such as PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components = 3)\n",
    "pca.fit(user_embeddings)\n",
    "user_embeddings_pca = pca.transform(user_embeddings)\n",
    "\n",
    "fig = plt.figure(figsize = (8,8))\n",
    "ax = fig.add_subplot(111, projection = \"3d\")\n",
    "xs, ys, zs = user_embeddings_pca[::150].T\n",
    "ax.scatter(xs, ys, zs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<pre>\n",
    "# Copyright 2018 Google Inc. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#      http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "</pre>"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf-gpu.1-15.m82",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf-gpu.1-15:m82"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
